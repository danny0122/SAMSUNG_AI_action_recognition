{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Br9F1os2dLkUqwIXwJjByzre2wXTez1W' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Br9F1os2dLkUqwIXwJjByzre2wXTez1W\" -O crop_mean.npy && rm -rf ~/cookies.txt\n",
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742\" -O data_split.pkl && rm -rf ~/cookies.txt\n",
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-\" -O dataset.tar.gz && rm -rf ~/cookies.txt\n",
    "!tar -zxvf dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from os.path import join\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#Run the code using selected GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_CHECK_POINT = 'check_point/'\n",
    "\n",
    "#Experiment, Optimization options\n",
    "DATA_SPLIT_PATH = 'data_split.pkl'\n",
    "BATCH_SIZE = 10\n",
    "NUM_CLASSES = 11\n",
    "CROP_SIZE = 112\n",
    "CHANNEL_NUM = 3\n",
    "CLIP_LENGTH = 16\n",
    "EPOCH_NUM = 50\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing : Define UCF11Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_LENGTH = 16\n",
    "\n",
    "np_mean = np.load('crop_mean.npy').reshape([CLIP_LENGTH, 112, 112, 3])\n",
    "\n",
    "def get_test_num(filename):\n",
    "    lines = open(filename, 'r')\n",
    "    return len(list(lines))\n",
    "\n",
    "def frame_process(clip, clip_length=CLIP_LENGTH, crop_size=112, channel_num=3):\n",
    "    frames_num = len(clip)\n",
    "    croped_frames = np.zeros([frames_num, crop_size, crop_size, channel_num]).astype(np.float32)\n",
    "\n",
    "\n",
    "    #Crop every frame into shape[crop_size, crop_size, channel_num]\n",
    "    for i in range(frames_num):\n",
    "        img = Image.fromarray(clip[i].astype(np.uint8))\n",
    "        if img.width > img.height:\n",
    "            scale = float(crop_size) / float(img.height)\n",
    "            img = np.array(cv2.resize(np.array(img), (int(img.width * scale + 1), crop_size))).astype(np.float32)\n",
    "        else:\n",
    "            scale = float(crop_size) / float(img.width)\n",
    "            img = np.array(cv2.resize(np.array(img), (crop_size, int(img.height * scale + 1)))).astype(np.float32)\n",
    "        crop_x = int((img.shape[0] - crop_size) / 2)\n",
    "        crop_y = int((img.shape[1] - crop_size) / 2)\n",
    "        img = img[crop_x: crop_x + crop_size, crop_y : crop_y + crop_size, :]\n",
    "        croped_frames[i, :, :, :] = img - np_mean[i]\n",
    "\n",
    "    return croped_frames\n",
    "\n",
    "\n",
    "def convert_images_to_clip(filename, clip_length=CLIP_LENGTH, crop_size=112, channel_num=3):\n",
    "    clip = []\n",
    "    for parent, dirnames, filenames in os.walk(filename):\n",
    "        filenames = sorted(filenames)\n",
    "        if len(filenames) < clip_length:\n",
    "            for i in range(0, len(filenames)):\n",
    "                image_name = str(filename) + '/' + str(filenames[i])\n",
    "                img = Image.open(image_name)\n",
    "                img_data = np.array(img)\n",
    "                clip.append(img_data)\n",
    "            for i in range(clip_length - len(filenames)):\n",
    "                image_name = str(filename) + '/' + str(filenames[len(filenames) - 1])\n",
    "                img = Image.open(image_name)\n",
    "                img_data = np.array(img)\n",
    "                clip.append(img_data)\n",
    "        else:\n",
    "            s_index = random.randint(0, len(filenames) - clip_length)\n",
    "            for i in range(s_index, s_index + clip_length):\n",
    "                image_name = str(filename) + '/' + str(filenames[i])\n",
    "                img = Image.open(image_name)\n",
    "                img_data = np.array(img)\n",
    "                clip.append(img_data)\n",
    "    if len(clip) == 0:\n",
    "        print(filename)\n",
    "    clip = frame_process(clip, clip_length, crop_size, channel_num)\n",
    "    return clip # shape: [clip_length, crop_size, crop_size, channel_num]\n",
    "\n",
    "class UCF11Dataset(Dataset):\n",
    "    def __init__(self, data_list, num_classes, crop_size=112, channel_num=3):\n",
    "        self.data_list = data_list\n",
    "        self.video_list = list(data_list)\n",
    "        self.crop_size = crop_size\n",
    "        self.channel_num = channel_num        \n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "    \n",
    "    def __getitem__(self, i):                \n",
    "        line = self.video_list[i].strip('\\n').split()\n",
    "        dirname = line[0]\n",
    "        label = int(self.data_list[dirname])\n",
    "        clips = convert_images_to_clip(dirname, CLIP_LENGTH, self.crop_size, self.channel_num)              \n",
    "        \n",
    "        clips = np.transpose(np.array(clips).astype(np.float32), (3, 0, 1, 2))\n",
    "        \n",
    "        batch_data = {'clips': clips, 'labels': label}\n",
    "        \n",
    "        return batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load UCF11(UCF YouTube Action) Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SPLIT_PATH = 'data_split.pkl'\n",
    "ucf11_dataset = pickle.load(open(DATA_SPLIT_PATH,'rb'))\n",
    "train_set = ucf11_dataset['train']\n",
    "test_set = ucf11_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_dataset = UCF11Dataset(train_set, NUM_CLASSES)\n",
    "test_video_dataset = UCF11Dataset(test_set, NUM_CLASSES)\n",
    "\n",
    "train_video_dataloader = DataLoader(train_video_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "test_video_dataloader = DataLoader(test_video_dataset, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NonLocal Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLocalBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, test_mode=False, dimension=3, sub_sample=True):\n",
    "        super(NonLocalBlock3D, self).__init__()\n",
    "        \n",
    "        self.test_mode = test_mode\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.inter_channels = in_channels // 2\n",
    "        if self.inter_channels == 0:\n",
    "            self.inter_channels = 1\n",
    "\n",
    "        max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "       \n",
    "        #============================================================\n",
    "        #make self.g , self.theta, self.phi\n",
    "        #these are nn.Conv3d, 1x1x1, stride=1, padding=0\n",
    "        #============================================================\n",
    "        self.g = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.theta = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.phi = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        #============================================================\n",
    "\n",
    "        #============================================================\n",
    "        #make self.W\n",
    "        #in this part, self.W.weight and self.W.bias must initialize to 0\n",
    "        #============================================================\n",
    "        self.W = nn.Conv3d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "        nn.init.constant_(self.W.weight, 0)\n",
    "        nn.init.constant_(self.W.bias, 0)\n",
    "        #============================================================\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
    "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "        batch_size = x.size(0)\n",
    "        #============================================================\n",
    "        #1. use self.g(x)\n",
    "        #2. use self.theta(x)\n",
    "        #3. use self.phi(x)\n",
    "        #4. several matrix multiplication between previous return value\n",
    "        #5. use self.W(y)\n",
    "        #6. make z with x and self.W(y)\n",
    "        #============================================================\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        \n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            print(\"x: {}\".format(x.shape))\n",
    "            print(\"g_x: {}\".format(g_x.shape))\n",
    "            print(\"theta_x: {}\".format(theta_x.shape))\n",
    "            print(\"phi_x: {}\".format(phi_x.shape))\n",
    "            print(\"f: {}\".format(f.shape))\n",
    "            print(\"y: {}\".format(y.shape))\n",
    "\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "        #============================================================\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define C3D Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=\"\"):\n",
    "        super(C3D, self).__init__()\n",
    "        \n",
    "        #============================================================\n",
    "        #All of convolution layers use kernel_size (3,3,3) and padding (1, 1, 1)\n",
    "        #conv1 3 -> 64\n",
    "        #conv2 64 -> 128\n",
    "        #conv3a 128 -> 256\n",
    "        #conv3b 256 -> 256\n",
    "        #conv4a 256 -> 512\n",
    "        #conv4b 512 -> 512\n",
    "        #conv5a 512 -> 512\n",
    "        #conv5b 512 -> 512\n",
    "        #fc6 (you need to find input channel size) -> 4096\n",
    "        #fc7 4096 -> num_classes\n",
    "        #============================================================\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.nonlocal1 = NonLocalBlock3D(64)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.nonlocal2 = NonLocalBlock3D(128)\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.nonlocal3 = NonLocalBlock3D(256)\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.nonlocal4 = NonLocalBlock3D(512)\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, num_classes)\n",
    "        #============================================================\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "        if pretrained:\n",
    "            self.__load_pretrained_weights(pretrained)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #============================================================\n",
    "        #use all layer to forward\n",
    "        #============================================================\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        #x = self.nonlocal1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        #x = self.nonlocal2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "        #x = self.nonlocal3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "        #x = self.nonlocal4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = x.view(-1, 8192)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #============================================================\n",
    "        logits = self.fc7(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def __load_pretrained_weights(self, model_path):\n",
    "        \"\"\"Initialiaze network.\"\"\"\n",
    "        corresp_name = {\n",
    "                        # Conv1\n",
    "                        \"features.0.weight\": \"conv1.weight\",\n",
    "                        \"features.0.bias\": \"conv1.bias\",\n",
    "                        # Conv2\n",
    "                        \"features.3.weight\": \"conv2.weight\",\n",
    "                        \"features.3.bias\": \"conv2.bias\",\n",
    "                        # Conv3a\n",
    "                        \"features.6.weight\": \"conv3a.weight\",\n",
    "                        \"features.6.bias\": \"conv3a.bias\",\n",
    "                        # Conv3b\n",
    "                        \"features.8.weight\": \"conv3b.weight\",\n",
    "                        \"features.8.bias\": \"conv3b.bias\",\n",
    "                        # Conv4a\n",
    "                        \"features.11.weight\": \"conv4a.weight\",\n",
    "                        \"features.11.bias\": \"conv4a.bias\",\n",
    "                        # Conv4b\n",
    "                        \"features.13.weight\": \"conv4b.weight\",\n",
    "                        \"features.13.bias\": \"conv4b.bias\",\n",
    "                        # Conv5a\n",
    "                        \"features.16.weight\": \"conv5a.weight\",\n",
    "                        \"features.16.bias\": \"conv5a.bias\",\n",
    "                         # Conv5b\n",
    "                        \"features.18.weight\": \"conv5b.weight\",\n",
    "                        \"features.18.bias\": \"conv5b.bias\",\n",
    "                        # fc6\n",
    "                        \"classifier.0.weight\": \"fc6.weight\",\n",
    "                        \"classifier.0.bias\": \"fc6.bias\",\n",
    "                        # fc7\n",
    "                        \"classifier.3.weight\": \"fc7.weight\",\n",
    "                        \"classifier.3.bias\": \"fc7.bias\",\n",
    "                        }\n",
    "\n",
    "        p_dict = torch.load(model_path)['state_dict']\n",
    "        s_dict = self.state_dict()\n",
    "        for name in p_dict:\n",
    "            if name not in corresp_name:\n",
    "                continue\n",
    "            s_dict[corresp_name[name]] = p_dict[name]\n",
    "        self.load_state_dict(s_dict)\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Network and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = C3D(num_classes=NUM_CLASSES)\n",
    "net = net.cuda()\n",
    "\n",
    "#net = C3D(num_classes=NUM_CLASSES).cuda()\n",
    "#net = torch.nn.DataParallel(net).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH_NUM):\n",
    "    # train\n",
    "    correct_epoch = 0\n",
    "    loss_epoch = 0\n",
    "    net.train()\n",
    "    \n",
    "    for i, batch in enumerate(train_video_dataloader):        \n",
    "        batch_clips = batch['clips']\n",
    "        batch_labels = batch['labels']\n",
    "        batch_clips = batch_clips.cuda()\n",
    "        batch_labels = batch_labels.cuda()\n",
    "        \n",
    "        logits = net(batch_clips)                \n",
    "\n",
    "        loss = F.cross_entropy(logits, batch_labels)\n",
    "        correct = (torch.argmax(logits, 1) == batch_labels).sum()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss\n",
    "        correct_epoch += correct\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('Epoch %d, Batch %d: Loss is %.5f; Accuracy is %.5f'%(epoch+1, i, loss, correct/batch_clips.shape[0]))\n",
    "            \n",
    "    print('Epoch %d: Average loss is: %.5f; Average accuracy is: %.5f'%(epoch+1, loss_epoch / len(train_video_dataloader),\n",
    "                                                                                correct_epoch / len(train_video_dataset)))\n",
    "                \n",
    "    # test\n",
    "    correct_epoch = 0\n",
    "    loss_epoch = 0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_video_dataloader):\n",
    "            batch_clips = batch['clips']\n",
    "            batch_labels = batch['labels']\n",
    "            batch_clips = batch_clips.cuda()\n",
    "            batch_labels = batch_labels.cuda()\n",
    "\n",
    "            logits = net(batch_clips)\n",
    "\n",
    "            loss = F.cross_entropy(logits, batch_labels)\n",
    "            correct = (torch.argmax(logits, 1) == batch_labels).sum()    \n",
    "\n",
    "            loss_epoch += loss\n",
    "            correct_epoch += correct\n",
    "        \n",
    "    print('Test loss is %.5f; Accuracy is %.5f'%(loss_epoch / len(test_video_dataloader),\n",
    "                                                                                correct_epoch / len(test_video_dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('samsung': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e7c3f763e218c31241ebf3a820e60d8ad9990019c62e2b485b53b4ae85ffac8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
