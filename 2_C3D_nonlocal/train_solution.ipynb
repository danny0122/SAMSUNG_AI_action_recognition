{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Br9F1os2dLkUqwIXwJjByzre2wXTez1W' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Br9F1os2dLkUqwIXwJjByzre2wXTez1W\" -O crop_mean.npy && rm -rf ~/cookies.txt\n",
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BnU8a7l9tGxZN7wVpeCQx0CIgutW-742\" -O data_split.pkl && rm -rf ~/cookies.txt\n",
    "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BQC3l22wya-sFYQMoUEYbmjhGZOYFZF-\" -O dataset.tar.gz && rm -rf ~/cookies.txt\n",
    "!tar -zxvf dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from os.path import join\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#Run the code using selected GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_CHECK_POINT = 'check_point/'\n",
    "\n",
    "#Experiment, Optimization options\n",
    "DATA_SPLIT_PATH = 'data_split.pkl'\n",
    "BATCH_SIZE = 10\n",
    "NUM_CLASSES = 11\n",
    "CROP_SIZE = 112\n",
    "CHANNEL_NUM = 3\n",
    "CLIP_LENGTH = 16\n",
    "EPOCH_NUM = 10\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing : Define UCF11Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_LENGTH = 16\n",
    "\n",
    "np_mean = np.load('crop_mean.npy').reshape([CLIP_LENGTH, 112, 112, 3])\n",
    "\n",
    "def get_test_num(filename):\n",
    "    lines = open(filename, 'r')\n",
    "    return len(list(lines))\n",
    "\n",
    "def frame_process(clip, clip_length=CLIP_LENGTH, crop_size=112, channel_num=3):\n",
    "    frames_num = len(clip)\n",
    "    croped_frames = np.zeros([frames_num, crop_size, crop_size, channel_num]).astype(np.float32)\n",
    "\n",
    "\n",
    "    #Crop every frame into shape[crop_size, crop_size, channel_num]\n",
    "    for i in range(frames_num):\n",
    "        img = Image.fromarray(clip[i].astype(np.uint8))\n",
    "        if img.width > img.height:\n",
    "            scale = float(crop_size) / float(img.height)\n",
    "            img = np.array(cv2.resize(np.array(img), (int(img.width * scale + 1), crop_size))).astype(np.float32)\n",
    "        else:\n",
    "            scale = float(crop_size) / float(img.width)\n",
    "            img = np.array(cv2.resize(np.array(img), (crop_size, int(img.height * scale + 1)))).astype(np.float32)\n",
    "        crop_x = int((img.shape[0] - crop_size) / 2)\n",
    "        crop_y = int((img.shape[1] - crop_size) / 2)\n",
    "        img = img[crop_x: crop_x + crop_size, crop_y : crop_y + crop_size, :]\n",
    "        croped_frames[i, :, :, :] = img - np_mean[i]\n",
    "\n",
    "    return croped_frames\n",
    "\n",
    "\n",
    "def convert_images_to_clip(filename, clip_length=CLIP_LENGTH, crop_size=112, channel_num=3):\n",
    "    clip = []\n",
    "    for parent, dirnames, filenames in os.walk(filename):\n",
    "        filenames = sorted(filenames)\n",
    "        if len(filenames) < clip_length:\n",
    "            for i in range(0, len(filenames)):\n",
    "                image_name = str(filename) + '/' + str(filenames[i])\n",
    "                img = Image.open(image_name)\n",
    "                img_data = np.array(img)\n",
    "                clip.append(img_data)\n",
    "            for i in range(clip_length - len(filenames)):\n",
    "                image_name = str(filename) + '/' + str(filenames[len(filenames) - 1])\n",
    "                img = Image.open(image_name)\n",
    "                img_data = np.array(img)\n",
    "                clip.append(img_data)\n",
    "        else:\n",
    "            s_index = random.randint(0, len(filenames) - clip_length)\n",
    "            for i in range(s_index, s_index + clip_length):\n",
    "                image_name = str(filename) + '/' + str(filenames[i])\n",
    "                img = Image.open(image_name)\n",
    "                img_data = np.array(img)\n",
    "                clip.append(img_data)\n",
    "    if len(clip) == 0:\n",
    "        print(filename)\n",
    "    clip = frame_process(clip, clip_length, crop_size, channel_num)\n",
    "    return clip # shape: [clip_length, crop_size, crop_size, channel_num]\n",
    "\n",
    "class UCF11Dataset(Dataset):\n",
    "    def __init__(self, data_list, num_classes, crop_size=112, channel_num=3):\n",
    "        self.data_list = data_list\n",
    "        self.video_list = list(data_list)\n",
    "        self.crop_size = crop_size\n",
    "        self.channel_num = channel_num        \n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "    \n",
    "    def __getitem__(self, i):                \n",
    "        line = self.video_list[i].strip('\\n').split()\n",
    "        dirname = line[0]\n",
    "        label = int(self.data_list[dirname])\n",
    "        clips = convert_images_to_clip(dirname, CLIP_LENGTH, self.crop_size, self.channel_num)              \n",
    "        \n",
    "        clips = np.transpose(np.array(clips).astype(np.float32), (3, 0, 1, 2))\n",
    "        \n",
    "        batch_data = {'clips': clips, 'labels': label}\n",
    "        \n",
    "        return batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load UCF11(UCF YouTube Action) Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SPLIT_PATH = 'data_split.pkl'\n",
    "ucf11_dataset = pickle.load(open(DATA_SPLIT_PATH,'rb'))\n",
    "train_set = ucf11_dataset['train']\n",
    "test_set = ucf11_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_dataset = UCF11Dataset(train_set, NUM_CLASSES)\n",
    "test_video_dataset = UCF11Dataset(test_set, NUM_CLASSES)\n",
    "\n",
    "train_video_dataloader = DataLoader(train_video_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "test_video_dataloader = DataLoader(test_video_dataset, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NonLocal Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLocalBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, test_mode=False, dimension=3, sub_sample=True):\n",
    "        super(NonLocalBlock3D, self).__init__()\n",
    "        \n",
    "        self.test_mode = test_mode\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample = sub_sample\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.inter_channels = in_channels // 2\n",
    "        if self.inter_channels == 0:\n",
    "            self.inter_channels = 1\n",
    "\n",
    "        max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "       \n",
    "        #============================================================\n",
    "        #make self.g , self.theta, self.phi\n",
    "        #these are nn.Conv3d, 1x1x1, stride=1, padding=0\n",
    "        #============================================================\n",
    "        self.g = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.theta = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.phi = nn.Conv3d(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0)\n",
    "        #============================================================\n",
    "\n",
    "        #============================================================\n",
    "        #make self.W\n",
    "        #in this part, self.W.weight and self.W.bias must initialize to 0\n",
    "        #============================================================\n",
    "        self.W = nn.Conv3d(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
    "                         kernel_size=1, stride=1, padding=0)\n",
    "        nn.init.constant_(self.W.weight, 0)\n",
    "        nn.init.constant_(self.W.bias, 0)\n",
    "        #============================================================\n",
    "\n",
    "        if sub_sample:\n",
    "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
    "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :return:\n",
    "        '''\n",
    "        batch_size = x.size(0)\n",
    "        #============================================================\n",
    "        #1. use self.g(x)\n",
    "        #2. use self.theta(x)\n",
    "        #3. use self.phi(x)\n",
    "        #4. several matrix multiplication between previous return value\n",
    "        #5. use self.W(y)\n",
    "        #6. make z with x and self.W(y)\n",
    "        #============================================================\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        \n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        \n",
    "        if self.test_mode:\n",
    "            print(\"x: {}\".format(x.shape))\n",
    "            print(\"g_x: {}\".format(g_x.shape))\n",
    "            print(\"theta_x: {}\".format(theta_x.shape))\n",
    "            print(\"phi_x: {}\".format(phi_x.shape))\n",
    "            print(\"f: {}\".format(f.shape))\n",
    "            print(\"y: {}\".format(y.shape))\n",
    "\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "        #============================================================\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define C3D Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D(nn.Module):\n",
    "    \"\"\"\n",
    "    The C3D network.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=\"\"):\n",
    "        super(C3D, self).__init__()\n",
    "        \n",
    "        #============================================================\n",
    "        #All of convolution layers use kernel_size (3,3,3) and padding (1, 1, 1)\n",
    "        #conv1 3 -> 64\n",
    "        #conv2 64 -> 128\n",
    "        #conv3a 128 -> 256\n",
    "        #conv3b 256 -> 256\n",
    "        #conv4a 256 -> 512\n",
    "        #conv4b 512 -> 512\n",
    "        #conv5a 512 -> 512\n",
    "        #conv5b 512 -> 512\n",
    "        #fc6 (you need to find input channel size) -> 4096\n",
    "        #fc7 4096 -> num_classes\n",
    "        #============================================================\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "        self.nonlocal1 = NonLocalBlock3D(64)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.nonlocal2 = NonLocalBlock3D(128)\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.nonlocal3 = NonLocalBlock3D(256)\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "        self.nonlocal4 = NonLocalBlock3D(512)\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, num_classes)\n",
    "        #============================================================\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.__init_weight()\n",
    "\n",
    "        if pretrained:\n",
    "            self.__load_pretrained_weights(pretrained)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #============================================================\n",
    "        #use all layer to forward\n",
    "        #============================================================\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        #x = self.nonlocal1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        #x = self.nonlocal2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "        #x = self.nonlocal3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "        #x = self.nonlocal4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = x.view(-1, 8192)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #============================================================\n",
    "        logits = self.fc7(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def __load_pretrained_weights(self, model_path):\n",
    "        \"\"\"Initialiaze network.\"\"\"\n",
    "        corresp_name = {\n",
    "                        # Conv1\n",
    "                        \"features.0.weight\": \"conv1.weight\",\n",
    "                        \"features.0.bias\": \"conv1.bias\",\n",
    "                        # Conv2\n",
    "                        \"features.3.weight\": \"conv2.weight\",\n",
    "                        \"features.3.bias\": \"conv2.bias\",\n",
    "                        # Conv3a\n",
    "                        \"features.6.weight\": \"conv3a.weight\",\n",
    "                        \"features.6.bias\": \"conv3a.bias\",\n",
    "                        # Conv3b\n",
    "                        \"features.8.weight\": \"conv3b.weight\",\n",
    "                        \"features.8.bias\": \"conv3b.bias\",\n",
    "                        # Conv4a\n",
    "                        \"features.11.weight\": \"conv4a.weight\",\n",
    "                        \"features.11.bias\": \"conv4a.bias\",\n",
    "                        # Conv4b\n",
    "                        \"features.13.weight\": \"conv4b.weight\",\n",
    "                        \"features.13.bias\": \"conv4b.bias\",\n",
    "                        # Conv5a\n",
    "                        \"features.16.weight\": \"conv5a.weight\",\n",
    "                        \"features.16.bias\": \"conv5a.bias\",\n",
    "                         # Conv5b\n",
    "                        \"features.18.weight\": \"conv5b.weight\",\n",
    "                        \"features.18.bias\": \"conv5b.bias\",\n",
    "                        # fc6\n",
    "                        \"classifier.0.weight\": \"fc6.weight\",\n",
    "                        \"classifier.0.bias\": \"fc6.bias\",\n",
    "                        # fc7\n",
    "                        \"classifier.3.weight\": \"fc7.weight\",\n",
    "                        \"classifier.3.bias\": \"fc7.bias\",\n",
    "                        }\n",
    "\n",
    "        p_dict = torch.load(model_path)['state_dict']\n",
    "        s_dict = self.state_dict()\n",
    "        for name in p_dict:\n",
    "            if name not in corresp_name:\n",
    "                continue\n",
    "            s_dict[corresp_name[name]] = p_dict[name]\n",
    "        self.load_state_dict(s_dict)\n",
    "\n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Network and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = C3D(num_classes=NUM_CLASSES)\n",
    "net = net.cuda()\n",
    "\n",
    "#net = C3D(num_classes=NUM_CLASSES).cuda()\n",
    "#net = torch.nn.DataParallel(net).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0: Loss is 77.89345; Accuracy is 0.00000\n",
      "Epoch 1, Batch 10: Loss is 5.74243; Accuracy is 0.30000\n",
      "Epoch 1, Batch 20: Loss is 2.42069; Accuracy is 0.10000\n",
      "Epoch 1, Batch 30: Loss is 2.63638; Accuracy is 0.10000\n",
      "Epoch 1, Batch 40: Loss is 2.80005; Accuracy is 0.10000\n",
      "Epoch 1, Batch 50: Loss is 2.43141; Accuracy is 0.00000\n",
      "Epoch 1, Batch 60: Loss is 2.24248; Accuracy is 0.10000\n",
      "Epoch 1, Batch 70: Loss is 2.16335; Accuracy is 0.30000\n",
      "Epoch 1, Batch 80: Loss is 2.07196; Accuracy is 0.30000\n",
      "Epoch 1, Batch 90: Loss is 2.23006; Accuracy is 0.40000\n",
      "Epoch 1, Batch 100: Loss is 2.24725; Accuracy is 0.30000\n",
      "Epoch 1, Batch 110: Loss is 2.11833; Accuracy is 0.10000\n",
      "Epoch 1: Average loss is: 11.64231; Average accuracy is: 0.16798\n",
      "Test loss is 2.09107; Accuracy is 0.27813\n",
      "Epoch 2, Batch 0: Loss is 1.54933; Accuracy is 0.50000\n",
      "Epoch 2, Batch 10: Loss is 2.08377; Accuracy is 0.30000\n",
      "Epoch 2, Batch 20: Loss is 1.92789; Accuracy is 0.40000\n",
      "Epoch 2, Batch 30: Loss is 2.04193; Accuracy is 0.10000\n",
      "Epoch 2, Batch 40: Loss is 1.26234; Accuracy is 0.60000\n",
      "Epoch 2, Batch 50: Loss is 1.55968; Accuracy is 0.50000\n",
      "Epoch 2, Batch 60: Loss is 1.23249; Accuracy is 0.70000\n",
      "Epoch 2, Batch 70: Loss is 1.39538; Accuracy is 0.50000\n",
      "Epoch 2, Batch 80: Loss is 1.89194; Accuracy is 0.30000\n",
      "Epoch 2, Batch 90: Loss is 2.03891; Accuracy is 0.10000\n",
      "Epoch 2, Batch 100: Loss is 1.58139; Accuracy is 0.50000\n",
      "Epoch 2, Batch 110: Loss is 1.88719; Accuracy is 0.40000\n",
      "Epoch 2: Average loss is: 1.78565; Average accuracy is: 0.38583\n",
      "Test loss is 1.85384; Accuracy is 0.44063\n",
      "Epoch 3, Batch 0: Loss is 1.35585; Accuracy is 0.60000\n",
      "Epoch 3, Batch 10: Loss is 1.35079; Accuracy is 0.30000\n",
      "Epoch 3, Batch 20: Loss is 1.91372; Accuracy is 0.30000\n",
      "Epoch 3, Batch 30: Loss is 1.77608; Accuracy is 0.20000\n",
      "Epoch 3, Batch 40: Loss is 1.44846; Accuracy is 0.30000\n",
      "Epoch 3, Batch 50: Loss is 1.12114; Accuracy is 0.70000\n",
      "Epoch 3, Batch 60: Loss is 2.01713; Accuracy is 0.30000\n",
      "Epoch 3, Batch 70: Loss is 1.26207; Accuracy is 0.70000\n",
      "Epoch 3, Batch 80: Loss is 1.93398; Accuracy is 0.30000\n",
      "Epoch 3, Batch 90: Loss is 2.35182; Accuracy is 0.10000\n",
      "Epoch 3, Batch 100: Loss is 1.42923; Accuracy is 0.70000\n",
      "Epoch 3, Batch 110: Loss is 2.57837; Accuracy is 0.30000\n",
      "Epoch 3: Average loss is: 1.44693; Average accuracy is: 0.49256\n",
      "Test loss is 2.03757; Accuracy is 0.39375\n",
      "Epoch 4, Batch 0: Loss is 0.97555; Accuracy is 0.70000\n",
      "Epoch 4, Batch 10: Loss is 0.97934; Accuracy is 0.70000\n",
      "Epoch 4, Batch 20: Loss is 1.00962; Accuracy is 0.60000\n",
      "Epoch 4, Batch 30: Loss is 1.00121; Accuracy is 0.60000\n",
      "Epoch 4, Batch 40: Loss is 0.89201; Accuracy is 0.70000\n",
      "Epoch 4, Batch 50: Loss is 0.71178; Accuracy is 0.80000\n",
      "Epoch 4, Batch 60: Loss is 1.22403; Accuracy is 0.60000\n",
      "Epoch 4, Batch 70: Loss is 0.93265; Accuracy is 0.60000\n",
      "Epoch 4, Batch 80: Loss is 1.35636; Accuracy is 0.60000\n",
      "Epoch 4, Batch 90: Loss is 1.35218; Accuracy is 0.60000\n",
      "Epoch 4, Batch 100: Loss is 1.12280; Accuracy is 0.60000\n",
      "Epoch 4, Batch 110: Loss is 1.63585; Accuracy is 0.60000\n",
      "Epoch 4: Average loss is: 1.17126; Average accuracy is: 0.60717\n",
      "Test loss is 1.98693; Accuracy is 0.38438\n",
      "Epoch 5, Batch 0: Loss is 0.81812; Accuracy is 0.70000\n",
      "Epoch 5, Batch 10: Loss is 1.10064; Accuracy is 0.50000\n",
      "Epoch 5, Batch 20: Loss is 1.43407; Accuracy is 0.60000\n",
      "Epoch 5, Batch 30: Loss is 0.85538; Accuracy is 0.60000\n",
      "Epoch 5, Batch 40: Loss is 1.76626; Accuracy is 0.50000\n",
      "Epoch 5, Batch 50: Loss is 1.63510; Accuracy is 0.30000\n",
      "Epoch 5, Batch 60: Loss is 1.11468; Accuracy is 0.80000\n",
      "Epoch 5, Batch 70: Loss is 2.85907; Accuracy is 0.30000\n",
      "Epoch 5, Batch 80: Loss is 0.67763; Accuracy is 0.80000\n",
      "Epoch 5, Batch 90: Loss is 0.77374; Accuracy is 0.70000\n",
      "Epoch 5, Batch 100: Loss is 1.14200; Accuracy is 0.50000\n",
      "Epoch 5, Batch 110: Loss is 1.57453; Accuracy is 0.30000\n",
      "Epoch 5: Average loss is: 1.00755; Average accuracy is: 0.65267\n",
      "Test loss is 1.86127; Accuracy is 0.50625\n",
      "Epoch 6, Batch 0: Loss is 1.18023; Accuracy is 0.50000\n",
      "Epoch 6, Batch 10: Loss is 0.23208; Accuracy is 1.00000\n",
      "Epoch 6, Batch 20: Loss is 1.60653; Accuracy is 0.50000\n",
      "Epoch 6, Batch 30: Loss is 1.25456; Accuracy is 0.40000\n",
      "Epoch 6, Batch 40: Loss is 1.24957; Accuracy is 0.50000\n",
      "Epoch 6, Batch 50: Loss is 1.02405; Accuracy is 0.70000\n",
      "Epoch 6, Batch 60: Loss is 0.30947; Accuracy is 1.00000\n",
      "Epoch 6, Batch 70: Loss is 0.81703; Accuracy is 0.70000\n",
      "Epoch 6, Batch 80: Loss is 0.75314; Accuracy is 0.80000\n",
      "Epoch 6, Batch 90: Loss is 1.02246; Accuracy is 0.70000\n",
      "Epoch 6, Batch 100: Loss is 1.14216; Accuracy is 0.50000\n",
      "Epoch 6, Batch 110: Loss is 0.92399; Accuracy is 0.60000\n",
      "Epoch 6: Average loss is: 0.82278; Average accuracy is: 0.72528\n",
      "Test loss is 1.99205; Accuracy is 0.44688\n",
      "Epoch 7, Batch 0: Loss is 0.63737; Accuracy is 0.90000\n",
      "Epoch 7, Batch 10: Loss is 1.19147; Accuracy is 0.70000\n",
      "Epoch 7, Batch 20: Loss is 0.56558; Accuracy is 0.80000\n",
      "Epoch 7, Batch 30: Loss is 0.64812; Accuracy is 0.80000\n",
      "Epoch 7, Batch 40: Loss is 0.22687; Accuracy is 0.90000\n",
      "Epoch 7, Batch 50: Loss is 0.60580; Accuracy is 0.60000\n",
      "Epoch 7, Batch 60: Loss is 0.69973; Accuracy is 0.80000\n",
      "Epoch 7, Batch 70: Loss is 0.07523; Accuracy is 1.00000\n",
      "Epoch 7, Batch 80: Loss is 0.86302; Accuracy is 0.60000\n",
      "Epoch 7, Batch 90: Loss is 0.23231; Accuracy is 1.00000\n",
      "Epoch 7, Batch 100: Loss is 1.78289; Accuracy is 0.50000\n",
      "Epoch 7, Batch 110: Loss is 0.53314; Accuracy is 0.90000\n",
      "Epoch 7: Average loss is: 0.67563; Average accuracy is: 0.77078\n",
      "Test loss is 2.43860; Accuracy is 0.48438\n",
      "Epoch 8, Batch 0: Loss is 0.58238; Accuracy is 0.70000\n",
      "Epoch 8, Batch 10: Loss is 0.51961; Accuracy is 0.70000\n",
      "Epoch 8, Batch 20: Loss is 1.11007; Accuracy is 0.70000\n",
      "Epoch 8, Batch 30: Loss is 0.58592; Accuracy is 0.80000\n",
      "Epoch 8, Batch 40: Loss is 0.24270; Accuracy is 0.90000\n",
      "Epoch 8, Batch 50: Loss is 0.28933; Accuracy is 0.90000\n",
      "Epoch 8, Batch 60: Loss is 0.26893; Accuracy is 0.90000\n",
      "Epoch 8, Batch 70: Loss is 0.83757; Accuracy is 0.60000\n",
      "Epoch 8, Batch 80: Loss is 0.06377; Accuracy is 1.00000\n",
      "Epoch 8, Batch 90: Loss is 0.46137; Accuracy is 0.80000\n",
      "Epoch 8, Batch 100: Loss is 0.36378; Accuracy is 0.90000\n",
      "Epoch 8, Batch 110: Loss is 0.47269; Accuracy is 0.90000\n",
      "Epoch 8: Average loss is: 0.53607; Average accuracy is: 0.82502\n",
      "Test loss is 2.46515; Accuracy is 0.47813\n",
      "Epoch 9, Batch 0: Loss is 0.24520; Accuracy is 0.90000\n",
      "Epoch 9, Batch 10: Loss is 0.58615; Accuracy is 0.70000\n",
      "Epoch 9, Batch 20: Loss is 0.10881; Accuracy is 1.00000\n",
      "Epoch 9, Batch 30: Loss is 0.29447; Accuracy is 0.90000\n",
      "Epoch 9, Batch 40: Loss is 0.55906; Accuracy is 0.80000\n",
      "Epoch 9, Batch 50: Loss is 0.27568; Accuracy is 0.90000\n",
      "Epoch 9, Batch 60: Loss is 0.79058; Accuracy is 0.80000\n",
      "Epoch 9, Batch 70: Loss is 0.14497; Accuracy is 1.00000\n",
      "Epoch 9, Batch 80: Loss is 0.44329; Accuracy is 0.80000\n",
      "Epoch 9, Batch 90: Loss is 0.25220; Accuracy is 1.00000\n",
      "Epoch 9, Batch 100: Loss is 0.38132; Accuracy is 0.80000\n",
      "Epoch 9, Batch 110: Loss is 0.23677; Accuracy is 0.90000\n",
      "Epoch 9: Average loss is: 0.54221; Average accuracy is: 0.82502\n",
      "Test loss is 2.08378; Accuracy is 0.52500\n",
      "Epoch 10, Batch 0: Loss is 0.08941; Accuracy is 1.00000\n",
      "Epoch 10, Batch 10: Loss is 0.63805; Accuracy is 0.60000\n",
      "Epoch 10, Batch 20: Loss is 0.10690; Accuracy is 1.00000\n",
      "Epoch 10, Batch 30: Loss is 0.03111; Accuracy is 1.00000\n",
      "Epoch 10, Batch 40: Loss is 0.80460; Accuracy is 0.80000\n",
      "Epoch 10, Batch 50: Loss is 0.26662; Accuracy is 0.80000\n",
      "Epoch 10, Batch 60: Loss is 0.26119; Accuracy is 0.80000\n",
      "Epoch 10, Batch 70: Loss is 0.13033; Accuracy is 0.90000\n",
      "Epoch 10, Batch 80: Loss is 0.08251; Accuracy is 1.00000\n",
      "Epoch 10, Batch 90: Loss is 0.47254; Accuracy is 0.90000\n",
      "Epoch 10, Batch 100: Loss is 1.30724; Accuracy is 0.60000\n",
      "Epoch 10, Batch 110: Loss is 0.35019; Accuracy is 0.90000\n",
      "Epoch 10: Average loss is: 0.38333; Average accuracy is: 0.86964\n",
      "Test loss is 2.40619; Accuracy is 0.52812\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH_NUM):\n",
    "    # train\n",
    "    correct_epoch = 0\n",
    "    loss_epoch = 0\n",
    "    net.train()\n",
    "    \n",
    "    for i, batch in enumerate(train_video_dataloader):        \n",
    "        batch_clips = batch['clips']\n",
    "        batch_labels = batch['labels']\n",
    "        batch_clips = batch_clips.cuda()\n",
    "        batch_labels = batch_labels.cuda()\n",
    "        \n",
    "        logits = net(batch_clips)                \n",
    "\n",
    "        loss = F.cross_entropy(logits, batch_labels)\n",
    "        correct = (torch.argmax(logits, 1) == batch_labels).sum()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_epoch += loss\n",
    "        correct_epoch += correct\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('Epoch %d, Batch %d: Loss is %.5f; Accuracy is %.5f'%(epoch+1, i, loss, correct/batch_clips.shape[0]))\n",
    "            \n",
    "    print('Epoch %d: Average loss is: %.5f; Average accuracy is: %.5f'%(epoch+1, loss_epoch / len(train_video_dataloader),\n",
    "                                                                                correct_epoch / len(train_video_dataset)))\n",
    "                \n",
    "    # test\n",
    "    correct_epoch = 0\n",
    "    loss_epoch = 0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_video_dataloader):\n",
    "            batch_clips = batch['clips']\n",
    "            batch_labels = batch['labels']\n",
    "            batch_clips = batch_clips.cuda()\n",
    "            batch_labels = batch_labels.cuda()\n",
    "\n",
    "            logits = net(batch_clips)\n",
    "\n",
    "            loss = F.cross_entropy(logits, batch_labels)\n",
    "            correct = (torch.argmax(logits, 1) == batch_labels).sum()    \n",
    "\n",
    "            loss_epoch += loss\n",
    "            correct_epoch += correct\n",
    "        \n",
    "    print('Test loss is %.5f; Accuracy is %.5f'%(loss_epoch / len(test_video_dataloader),\n",
    "                                                                                correct_epoch / len(test_video_dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('samsung': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e7c3f763e218c31241ebf3a820e60d8ad9990019c62e2b485b53b4ae85ffac8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
